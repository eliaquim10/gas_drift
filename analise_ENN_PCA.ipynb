{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise de dados de concetracao de gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from processamento import evaluate_models, MyPCA, PCA\n",
    "\n",
    "# Classes dos modelo\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "# Funções de avaliação dos modelos\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "# o \"k\" do enn e o \"k\" podem ter alguma relacao, o k encontrado no treino do knn pode ser usado no enn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V121</th>\n",
       "      <th>V122</th>\n",
       "      <th>V123</th>\n",
       "      <th>V124</th>\n",
       "      <th>V125</th>\n",
       "      <th>V126</th>\n",
       "      <th>V127</th>\n",
       "      <th>V128</th>\n",
       "      <th>V129</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12285.6582</td>\n",
       "      <td>4.076635</td>\n",
       "      <td>4.842317</td>\n",
       "      <td>7.509393</td>\n",
       "      <td>10.822436</td>\n",
       "      <td>-1.312657</td>\n",
       "      <td>-1.853717</td>\n",
       "      <td>-6.924985</td>\n",
       "      <td>11800.9233</td>\n",
       "      <td>4.483500</td>\n",
       "      <td>...</td>\n",
       "      <td>1784.5324</td>\n",
       "      <td>1.907000</td>\n",
       "      <td>1.729200</td>\n",
       "      <td>4.881194</td>\n",
       "      <td>8.623828</td>\n",
       "      <td>-0.314110</td>\n",
       "      <td>-0.661556</td>\n",
       "      <td>-3.521663</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-35.6889</td>\n",
       "      <td>0.993944</td>\n",
       "      <td>0.166099</td>\n",
       "      <td>0.489363</td>\n",
       "      <td>3.484663</td>\n",
       "      <td>-0.130298</td>\n",
       "      <td>-0.528364</td>\n",
       "      <td>-3.735347</td>\n",
       "      <td>266.4145</td>\n",
       "      <td>1.053988</td>\n",
       "      <td>...</td>\n",
       "      <td>904.9898</td>\n",
       "      <td>1.433707</td>\n",
       "      <td>1.068069</td>\n",
       "      <td>2.532958</td>\n",
       "      <td>5.369720</td>\n",
       "      <td>-0.183779</td>\n",
       "      <td>-0.534087</td>\n",
       "      <td>-4.635975</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63927.2217</td>\n",
       "      <td>14.956941</td>\n",
       "      <td>19.971376</td>\n",
       "      <td>29.188512</td>\n",
       "      <td>33.291320</td>\n",
       "      <td>-10.433776</td>\n",
       "      <td>-16.062245</td>\n",
       "      <td>-49.490143</td>\n",
       "      <td>57405.8483</td>\n",
       "      <td>15.613843</td>\n",
       "      <td>...</td>\n",
       "      <td>14585.7879</td>\n",
       "      <td>8.189021</td>\n",
       "      <td>6.099452</td>\n",
       "      <td>12.127991</td>\n",
       "      <td>15.709651</td>\n",
       "      <td>-3.887082</td>\n",
       "      <td>-6.731473</td>\n",
       "      <td>-19.326895</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2992.9019</td>\n",
       "      <td>1.380553</td>\n",
       "      <td>0.808910</td>\n",
       "      <td>1.288259</td>\n",
       "      <td>4.660135</td>\n",
       "      <td>-0.755903</td>\n",
       "      <td>-1.120470</td>\n",
       "      <td>-4.075213</td>\n",
       "      <td>4301.4033</td>\n",
       "      <td>1.652701</td>\n",
       "      <td>...</td>\n",
       "      <td>6044.5554</td>\n",
       "      <td>3.488295</td>\n",
       "      <td>2.662288</td>\n",
       "      <td>5.938297</td>\n",
       "      <td>8.544508</td>\n",
       "      <td>-1.567322</td>\n",
       "      <td>-2.701235</td>\n",
       "      <td>-6.472439</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57524.7812</td>\n",
       "      <td>11.912566</td>\n",
       "      <td>14.631496</td>\n",
       "      <td>19.809240</td>\n",
       "      <td>23.715868</td>\n",
       "      <td>-9.084750</td>\n",
       "      <td>-11.770585</td>\n",
       "      <td>-39.234003</td>\n",
       "      <td>50051.0703</td>\n",
       "      <td>11.732548</td>\n",
       "      <td>...</td>\n",
       "      <td>10580.1006</td>\n",
       "      <td>5.752675</td>\n",
       "      <td>3.880740</td>\n",
       "      <td>8.545897</td>\n",
       "      <td>11.831716</td>\n",
       "      <td>-2.655521</td>\n",
       "      <td>-4.312744</td>\n",
       "      <td>-8.510591</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1         V2         V3         V4         V5         V6  \\\n",
       "0  12285.6582   4.076635   4.842317   7.509393  10.822436  -1.312657   \n",
       "1    -35.6889   0.993944   0.166099   0.489363   3.484663  -0.130298   \n",
       "2  63927.2217  14.956941  19.971376  29.188512  33.291320 -10.433776   \n",
       "3   2992.9019   1.380553   0.808910   1.288259   4.660135  -0.755903   \n",
       "4  57524.7812  11.912566  14.631496  19.809240  23.715868  -9.084750   \n",
       "\n",
       "          V7         V8          V9        V10  ...        V121      V122  \\\n",
       "0  -1.853717  -6.924985  11800.9233   4.483500  ...   1784.5324  1.907000   \n",
       "1  -0.528364  -3.735347    266.4145   1.053988  ...    904.9898  1.433707   \n",
       "2 -16.062245 -49.490143  57405.8483  15.613843  ...  14585.7879  8.189021   \n",
       "3  -1.120470  -4.075213   4301.4033   1.652701  ...   6044.5554  3.488295   \n",
       "4 -11.770585 -39.234003  50051.0703  11.732548  ...  10580.1006  5.752675   \n",
       "\n",
       "       V123       V124       V125      V126      V127       V128   V129  Class  \n",
       "0  1.729200   4.881194   8.623828 -0.314110 -0.661556  -3.521663   10.0      4  \n",
       "1  1.068069   2.532958   5.369720 -0.183779 -0.534087  -4.635975   50.0      3  \n",
       "2  6.099452  12.127991  15.709651 -3.887082 -6.731473 -19.326895  250.0      4  \n",
       "3  2.662288   5.938297   8.544508 -1.567322 -2.701235  -6.472439  600.0      3  \n",
       "4  3.880740   8.545897  11.831716 -2.655521 -4.312744  -8.510591  150.0      4  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = pd.read_csv(\"dataset_57_hypothyroid.csv\")\n",
    "dataset = pd.read_csv(\"phpN4gaxw.csv\")\n",
    "dataset.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13910, 130)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13910, 130)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3009\n",
       "2    2926\n",
       "1    2565\n",
       "4    1936\n",
       "6    1833\n",
       "3    1641\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop([\"Class\"], axis=1)\n",
    "y = dataset[\"Class\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "  MLPClassifier(),\n",
    "  KNeighborsClassifier(),\n",
    "  SVC(),\n",
    "  DecisionTreeClassifier(),\n",
    "  GaussianNB(),\n",
    "]\n",
    "# params = [ { \"hidden_layer_sizes\": list(range(10, 100, 10)), \"activation\":[\"logistic\", \"tanh\", \"relu\"], \"learning_rate_init\":[0.0001], \"max_iter\":[200], \"verbose\": [False] }, { \"n_neighbors\": np.arange(1,11, 2), \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"] }, { \"kernel\": [\"linear\", \"poly\", \"sigmoid\", \"rbf\"], \"verbose\": [False], \"probability\": [True]},{\"criterion\": [\"gini\", \"entropy\"],}, {}, ]\n",
    "\n",
    "params = [\n",
    "  {\n",
    "    \"hidden_layer_sizes\": [90], \n",
    "    \"activation\":[\"tanh\"],\n",
    "    \"learning_rate_init\":[0.0001],\n",
    "    \"max_iter\":[200],\n",
    "    \"verbose\": [False]\n",
    "  },\n",
    "  {\n",
    "    \"n_neighbors\": [3],\n",
    "    \"metric\": [\"euclidean\"]\n",
    "  },\n",
    "  {\n",
    "    \"kernel\": [\"poly\"], # \"rbf\",\n",
    "    \"verbose\": [False],\n",
    "    \"probability\": [True]\n",
    "  },\n",
    "  {\n",
    "    \"criterion\": [\"entropy\"],\n",
    "  },\n",
    "  {\n",
    "  },\n",
    "]\n",
    "params_enn = {\"n_neighbors\": 5, \"sampling_strategy\": \"auto\", \"kind_sel\": \"mode\"}\n",
    "params_pca = {\"n_components\": 50, \"svd_solver\": \"auto\", \"iterated_power\": \"auto\", \"random_state\": 1}\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True, random_state=1)\n",
    "resultado = evaluate_models(models, params, X, y, skf, params_enn, params_pca) #, params_enn, params_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC</th>\n",
       "      <th>Acuracia</th>\n",
       "      <th>F1</th>\n",
       "      <th>tempo(s) treino</th>\n",
       "      <th>tempo(s) predição</th>\n",
       "      <th>matriz</th>\n",
       "      <th>hiper paramentros</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.84</td>\n",
       "      <td>99.06</td>\n",
       "      <td>99.00</td>\n",
       "      <td>5745.470340</td>\n",
       "      <td>1.428420</td>\n",
       "      <td>[[255.0, 0.3, 0.1, 0.6, 0.4, 0.1], [0.6, 289.9...</td>\n",
       "      <td>[{'activation': 'tanh', 'hidden_layer_sizes': ...</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.63</td>\n",
       "      <td>99.16</td>\n",
       "      <td>99.14</td>\n",
       "      <td>394.072550</td>\n",
       "      <td>47.708730</td>\n",
       "      <td>[[254.3, 0.8, 0.0, 0.8, 0.6, 0.0], [0.7, 290.9...</td>\n",
       "      <td>[{'metric': 'euclidean', 'n_neighbors': 3}, {'...</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.14</td>\n",
       "      <td>89.02</td>\n",
       "      <td>89.16</td>\n",
       "      <td>7379.636340</td>\n",
       "      <td>60.424810</td>\n",
       "      <td>[[207.9, 1.2, 0.4, 45.6, 1.0, 0.4], [0.3, 279....</td>\n",
       "      <td>[{'kernel': 'poly', 'probability': True, 'verb...</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.22</td>\n",
       "      <td>97.17</td>\n",
       "      <td>96.99</td>\n",
       "      <td>673.649410</td>\n",
       "      <td>0.968580</td>\n",
       "      <td>[[250.6, 0.9, 0.4, 1.7, 1.6, 1.3], [0.7, 287.7...</td>\n",
       "      <td>[{'criterion': 'entropy'}, {'criterion': 'entr...</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.25</td>\n",
       "      <td>67.71</td>\n",
       "      <td>69.13</td>\n",
       "      <td>223.178430</td>\n",
       "      <td>1.183720</td>\n",
       "      <td>[[173.6, 4.0, 0.9, 61.3, 5.1, 11.6], [3.2, 162...</td>\n",
       "      <td>[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ROC Acuracia     F1 tempo(s) treino tempo(s) predição  \\\n",
       "0  99.84    99.06  99.00     5745.470340          1.428420   \n",
       "1  99.63    99.16  99.14      394.072550         47.708730   \n",
       "2  99.14    89.02  89.16     7379.636340         60.424810   \n",
       "3  98.22    97.17  96.99      673.649410          0.968580   \n",
       "4  90.25    67.71  69.13      223.178430          1.183720   \n",
       "\n",
       "                                              matriz  \\\n",
       "0  [[255.0, 0.3, 0.1, 0.6, 0.4, 0.1], [0.6, 289.9...   \n",
       "1  [[254.3, 0.8, 0.0, 0.8, 0.6, 0.0], [0.7, 290.9...   \n",
       "2  [[207.9, 1.2, 0.4, 45.6, 1.0, 0.4], [0.3, 279....   \n",
       "3  [[250.6, 0.9, 0.4, 1.7, 1.6, 1.3], [0.7, 287.7...   \n",
       "4  [[173.6, 4.0, 0.9, 61.3, 5.1, 11.6], [3.2, 162...   \n",
       "\n",
       "                                   hiper paramentros                    modelo  \n",
       "0  [{'activation': 'tanh', 'hidden_layer_sizes': ...           MLPClassifier()  \n",
       "1  [{'metric': 'euclidean', 'n_neighbors': 3}, {'...    KNeighborsClassifier()  \n",
       "2  [{'kernel': 'poly', 'probability': True, 'verb...                     SVC()  \n",
       "3  [{'criterion': 'entropy'}, {'criterion': 'entr...  DecisionTreeClassifier()  \n",
       "4           [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]              GaussianNB()  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_pd = pd.DataFrame(resultado)\n",
    "resultado_pd.columns = [\"ROC\", \"Acuracia\", \"F1\", \"tempo(s) treino\",\"tempo(s) predição\", \"matriz\", \"hiper paramentros\", \"modelo\"]\n",
    "resultado_pd[\"ROC\"] = resultado_pd[\"ROC\"].apply(lambda x:  \"%.2f\" % (float(x)*100))  \n",
    "resultado_pd[\"Acuracia\"] = resultado_pd[\"Acuracia\"].apply(lambda x:  \"%.2f\" % (float(x)*100))  \n",
    "resultado_pd[\"F1\"] = resultado_pd[\"F1\"].apply(lambda x:  \"%.2f\" % (float(x)*100))  \n",
    "resultado_pd[\"tempo(s) treino\"] = resultado_pd[\"tempo(s) treino\"].apply(lambda x:  \"%.6f\" % (float(x)*100))  \n",
    "resultado_pd[\"tempo(s) predição\"] = resultado_pd[\"tempo(s) predição\"].apply(lambda x:  \"%.6f\" % (float(x)*100))  \n",
    "resultado_pd.to_csv(\"resultados_best.csv\") # adiciona svm\n",
    "resultado_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC</th>\n",
       "      <th>Acuracia</th>\n",
       "      <th>F1</th>\n",
       "      <th>tempo(s) treino</th>\n",
       "      <th>tempo(s) predição</th>\n",
       "      <th>matriz</th>\n",
       "      <th>hiper paramentros</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.84</td>\n",
       "      <td>99.06</td>\n",
       "      <td>99.00</td>\n",
       "      <td>5745.470340</td>\n",
       "      <td>1.428420</td>\n",
       "      <td>[[255.0, 0.3, 0.1, 0.6, 0.4, 0.1], [0.6, 289.9...</td>\n",
       "      <td>[{'activation': 'tanh', 'hidden_layer_sizes': ...</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.63</td>\n",
       "      <td>99.16</td>\n",
       "      <td>99.14</td>\n",
       "      <td>394.072550</td>\n",
       "      <td>47.708730</td>\n",
       "      <td>[[254.3, 0.8, 0.0, 0.8, 0.6, 0.0], [0.7, 290.9...</td>\n",
       "      <td>[{'metric': 'euclidean', 'n_neighbors': 3}, {'...</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.14</td>\n",
       "      <td>89.02</td>\n",
       "      <td>89.16</td>\n",
       "      <td>7379.636340</td>\n",
       "      <td>60.424810</td>\n",
       "      <td>[[207.9, 1.2, 0.4, 45.6, 1.0, 0.4], [0.3, 279....</td>\n",
       "      <td>[{'kernel': 'poly', 'probability': True, 'verb...</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.22</td>\n",
       "      <td>97.17</td>\n",
       "      <td>96.99</td>\n",
       "      <td>673.649410</td>\n",
       "      <td>0.968580</td>\n",
       "      <td>[[250.6, 0.9, 0.4, 1.7, 1.6, 1.3], [0.7, 287.7...</td>\n",
       "      <td>[{'criterion': 'entropy'}, {'criterion': 'entr...</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.25</td>\n",
       "      <td>67.71</td>\n",
       "      <td>69.13</td>\n",
       "      <td>223.178430</td>\n",
       "      <td>1.183720</td>\n",
       "      <td>[[173.6, 4.0, 0.9, 61.3, 5.1, 11.6], [3.2, 162...</td>\n",
       "      <td>[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ROC Acuracia     F1 tempo(s) treino tempo(s) predição  \\\n",
       "0  99.84    99.06  99.00     5745.470340          1.428420   \n",
       "1  99.63    99.16  99.14      394.072550         47.708730   \n",
       "2  99.14    89.02  89.16     7379.636340         60.424810   \n",
       "3  98.22    97.17  96.99      673.649410          0.968580   \n",
       "4  90.25    67.71  69.13      223.178430          1.183720   \n",
       "\n",
       "                                              matriz  \\\n",
       "0  [[255.0, 0.3, 0.1, 0.6, 0.4, 0.1], [0.6, 289.9...   \n",
       "1  [[254.3, 0.8, 0.0, 0.8, 0.6, 0.0], [0.7, 290.9...   \n",
       "2  [[207.9, 1.2, 0.4, 45.6, 1.0, 0.4], [0.3, 279....   \n",
       "3  [[250.6, 0.9, 0.4, 1.7, 1.6, 1.3], [0.7, 287.7...   \n",
       "4  [[173.6, 4.0, 0.9, 61.3, 5.1, 11.6], [3.2, 162...   \n",
       "\n",
       "                                   hiper paramentros                    modelo  \n",
       "0  [{'activation': 'tanh', 'hidden_layer_sizes': ...           MLPClassifier()  \n",
       "1  [{'metric': 'euclidean', 'n_neighbors': 3}, {'...    KNeighborsClassifier()  \n",
       "2  [{'kernel': 'poly', 'probability': True, 'verb...                     SVC()  \n",
       "3  [{'criterion': 'entropy'}, {'criterion': 'entr...  DecisionTreeClassifier()  \n",
       "4           [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]              GaussianNB()  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resultado_pd.drop(\"matriz\", axis=1).to_csv(\"resultados_best_sem_matriz.csv\")\n",
    "resultado_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resultado_pd[\"matriz\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matriz(matrizes, model):\n",
    "    for ma, mo in zip(matrizes, model):\n",
    "        matriz = pd.DataFrame(ma)\n",
    "        matriz.columns = list(range(1,7))\n",
    "        matriz.index = list(range(1,7))\n",
    "        matriz.to_csv(\"matrizes_best/matriz_{}.csv\".format(mo[:-2]))\n",
    "\n",
    "save_matriz(resultado_pd[\"matriz\"], resultado_pd[\"modelo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f6ca866bada2297d8fd83be4f6138ccbd7745b9651ccd132432817d094bcf3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
