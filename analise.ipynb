{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise de dados de concetracao de gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from processamento import evaluate_models, MyPCA, PCA\n",
    "\n",
    "# Classes dos modelo\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "# Funções de avaliação dos modelos\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "# o \"k\" do enn e o \"k\" podem ter alguma relacao, o k encontrado no treino do knn pode ser usado no enn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V121</th>\n",
       "      <th>V122</th>\n",
       "      <th>V123</th>\n",
       "      <th>V124</th>\n",
       "      <th>V125</th>\n",
       "      <th>V126</th>\n",
       "      <th>V127</th>\n",
       "      <th>V128</th>\n",
       "      <th>V129</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12285.6582</td>\n",
       "      <td>4.076635</td>\n",
       "      <td>4.842317</td>\n",
       "      <td>7.509393</td>\n",
       "      <td>10.822436</td>\n",
       "      <td>-1.312657</td>\n",
       "      <td>-1.853717</td>\n",
       "      <td>-6.924985</td>\n",
       "      <td>11800.9233</td>\n",
       "      <td>4.483500</td>\n",
       "      <td>...</td>\n",
       "      <td>1784.5324</td>\n",
       "      <td>1.907000</td>\n",
       "      <td>1.729200</td>\n",
       "      <td>4.881194</td>\n",
       "      <td>8.623828</td>\n",
       "      <td>-0.314110</td>\n",
       "      <td>-0.661556</td>\n",
       "      <td>-3.521663</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-35.6889</td>\n",
       "      <td>0.993944</td>\n",
       "      <td>0.166099</td>\n",
       "      <td>0.489363</td>\n",
       "      <td>3.484663</td>\n",
       "      <td>-0.130298</td>\n",
       "      <td>-0.528364</td>\n",
       "      <td>-3.735347</td>\n",
       "      <td>266.4145</td>\n",
       "      <td>1.053988</td>\n",
       "      <td>...</td>\n",
       "      <td>904.9898</td>\n",
       "      <td>1.433707</td>\n",
       "      <td>1.068069</td>\n",
       "      <td>2.532958</td>\n",
       "      <td>5.369720</td>\n",
       "      <td>-0.183779</td>\n",
       "      <td>-0.534087</td>\n",
       "      <td>-4.635975</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63927.2217</td>\n",
       "      <td>14.956941</td>\n",
       "      <td>19.971376</td>\n",
       "      <td>29.188512</td>\n",
       "      <td>33.291320</td>\n",
       "      <td>-10.433776</td>\n",
       "      <td>-16.062245</td>\n",
       "      <td>-49.490143</td>\n",
       "      <td>57405.8483</td>\n",
       "      <td>15.613843</td>\n",
       "      <td>...</td>\n",
       "      <td>14585.7879</td>\n",
       "      <td>8.189021</td>\n",
       "      <td>6.099452</td>\n",
       "      <td>12.127991</td>\n",
       "      <td>15.709651</td>\n",
       "      <td>-3.887082</td>\n",
       "      <td>-6.731473</td>\n",
       "      <td>-19.326895</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2992.9019</td>\n",
       "      <td>1.380553</td>\n",
       "      <td>0.808910</td>\n",
       "      <td>1.288259</td>\n",
       "      <td>4.660135</td>\n",
       "      <td>-0.755903</td>\n",
       "      <td>-1.120470</td>\n",
       "      <td>-4.075213</td>\n",
       "      <td>4301.4033</td>\n",
       "      <td>1.652701</td>\n",
       "      <td>...</td>\n",
       "      <td>6044.5554</td>\n",
       "      <td>3.488295</td>\n",
       "      <td>2.662288</td>\n",
       "      <td>5.938297</td>\n",
       "      <td>8.544508</td>\n",
       "      <td>-1.567322</td>\n",
       "      <td>-2.701235</td>\n",
       "      <td>-6.472439</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57524.7812</td>\n",
       "      <td>11.912566</td>\n",
       "      <td>14.631496</td>\n",
       "      <td>19.809240</td>\n",
       "      <td>23.715868</td>\n",
       "      <td>-9.084750</td>\n",
       "      <td>-11.770585</td>\n",
       "      <td>-39.234003</td>\n",
       "      <td>50051.0703</td>\n",
       "      <td>11.732548</td>\n",
       "      <td>...</td>\n",
       "      <td>10580.1006</td>\n",
       "      <td>5.752675</td>\n",
       "      <td>3.880740</td>\n",
       "      <td>8.545897</td>\n",
       "      <td>11.831716</td>\n",
       "      <td>-2.655521</td>\n",
       "      <td>-4.312744</td>\n",
       "      <td>-8.510591</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1         V2         V3         V4         V5         V6  \\\n",
       "0  12285.6582   4.076635   4.842317   7.509393  10.822436  -1.312657   \n",
       "1    -35.6889   0.993944   0.166099   0.489363   3.484663  -0.130298   \n",
       "2  63927.2217  14.956941  19.971376  29.188512  33.291320 -10.433776   \n",
       "3   2992.9019   1.380553   0.808910   1.288259   4.660135  -0.755903   \n",
       "4  57524.7812  11.912566  14.631496  19.809240  23.715868  -9.084750   \n",
       "\n",
       "          V7         V8          V9        V10  ...        V121      V122  \\\n",
       "0  -1.853717  -6.924985  11800.9233   4.483500  ...   1784.5324  1.907000   \n",
       "1  -0.528364  -3.735347    266.4145   1.053988  ...    904.9898  1.433707   \n",
       "2 -16.062245 -49.490143  57405.8483  15.613843  ...  14585.7879  8.189021   \n",
       "3  -1.120470  -4.075213   4301.4033   1.652701  ...   6044.5554  3.488295   \n",
       "4 -11.770585 -39.234003  50051.0703  11.732548  ...  10580.1006  5.752675   \n",
       "\n",
       "       V123       V124       V125      V126      V127       V128   V129  Class  \n",
       "0  1.729200   4.881194   8.623828 -0.314110 -0.661556  -3.521663   10.0      4  \n",
       "1  1.068069   2.532958   5.369720 -0.183779 -0.534087  -4.635975   50.0      3  \n",
       "2  6.099452  12.127991  15.709651 -3.887082 -6.731473 -19.326895  250.0      4  \n",
       "3  2.662288   5.938297   8.544508 -1.567322 -2.701235  -6.472439  600.0      3  \n",
       "4  3.880740   8.545897  11.831716 -2.655521 -4.312744  -8.510591  150.0      4  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = pd.read_csv(\"dataset_57_hypothyroid.csv\")\n",
    "dataset = pd.read_csv(\"phpN4gaxw.csv\")\n",
    "dataset.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13910, 130)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13910, 130)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3009\n",
       "2    2926\n",
       "1    2565\n",
       "4    1936\n",
       "6    1833\n",
       "3    1641\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop([\"Class\"], axis=1)\n",
    "y = dataset[\"Class\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']) ~~~~~~~~~~\n",
      "============================== MLPClassifier() ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emn3\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001, 'max_iter': 200, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']) ~~~~~~~~~~\n",
      "============================== KNeighborsClassifier() ==============================\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']) ~~~~~~~~~~\n",
      "============================== SVC() ==============================\n",
      "{'kernel': 'poly', 'probability': True, 'verbose': False}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']) ~~~~~~~~~~\n",
      "============================== DecisionTreeClassifier() ==============================\n",
      "{'criterion': 'entropy'}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n",
      "12519 1391\n",
      "~~~~~~~~~~ dict_keys(['priors', 'var_smoothing']) ~~~~~~~~~~\n",
      "============================== GaussianNB() ==============================\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "  MLPClassifier(),\n",
    "  KNeighborsClassifier(),\n",
    "  SVC(),\n",
    "  DecisionTreeClassifier(),\n",
    "  GaussianNB(),\n",
    "]\n",
    "# params = [ { \"hidden_layer_sizes\": list(range(10, 100, 10)), \"activation\":[\"logistic\", \"tanh\", \"relu\"], \"learning_rate_init\":[0.0001], \"max_iter\":[200], \"verbose\": [False] }, { \"n_neighbors\": np.arange(1,11, 2), \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"] }, { \"kernel\": [\"linear\", \"poly\", \"sigmoid\", \"rbf\"], \"verbose\": [False], \"probability\": [True]},{\"criterion\": [\"gini\", \"entropy\"],}, {}, ]\n",
    "\n",
    "params = [\n",
    "  {\n",
    "    \"hidden_layer_sizes\": [90], \n",
    "    \"activation\":[\"tanh\"],\n",
    "    \"learning_rate_init\":[0.0001],\n",
    "    \"max_iter\":[200],\n",
    "    \"verbose\": [False]\n",
    "  },\n",
    "  {\n",
    "    \"n_neighbors\": [3],\n",
    "    \"metric\": [\"euclidean\"]\n",
    "  },\n",
    "  {\n",
    "    \"kernel\": [\"poly\"], # \"rbf\",\n",
    "    \"verbose\": [False],\n",
    "    \"probability\": [True]\n",
    "  },\n",
    "  {\n",
    "    \"criterion\": [\"entropy\"],\n",
    "  },\n",
    "  {\n",
    "  },\n",
    "]\n",
    "editedNearestNeighbours = EditedNearestNeighbours(n_neighbors=5, sampling_strategy=\"auto\", kind_sel=\"mode\")\n",
    "params_pca = {\"n_components\": 50, \"svd_solver\": \"auto\", \"iterated_power\": \"auto\", \"random_state\": 1}\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True, random_state=1)\n",
    "resultado = evaluate_models(models, params, X, y, skf, editedNearestNeighbours, params_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC</th>\n",
       "      <th>Acuracia</th>\n",
       "      <th>F1</th>\n",
       "      <th>tempo(s) treino</th>\n",
       "      <th>tempo(s) predição</th>\n",
       "      <th>matriz</th>\n",
       "      <th>hiper paramentros</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.90</td>\n",
       "      <td>99.14</td>\n",
       "      <td>99.08</td>\n",
       "      <td>6113.609690</td>\n",
       "      <td>1.533610</td>\n",
       "      <td>[[255.3, 0.1, 0.2, 0.2, 0.6, 0.1], [0.3, 290.5...</td>\n",
       "      <td>[{'activation': 'tanh', 'hidden_layer_sizes': ...</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.65</td>\n",
       "      <td>99.15</td>\n",
       "      <td>99.12</td>\n",
       "      <td>196.105840</td>\n",
       "      <td>46.677820</td>\n",
       "      <td>[[254.8, 0.9, 0.0, 0.2, 0.6, 0.0], [0.3, 291.4...</td>\n",
       "      <td>[{'metric': 'euclidean', 'n_neighbors': 3}, {'...</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.08</td>\n",
       "      <td>88.58</td>\n",
       "      <td>88.72</td>\n",
       "      <td>7816.920090</td>\n",
       "      <td>65.981150</td>\n",
       "      <td>[[208.6, 1.1, 0.5, 44.6, 1.4, 0.3], [0.4, 278....</td>\n",
       "      <td>[{'kernel': 'poly', 'probability': True, 'verb...</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.73</td>\n",
       "      <td>96.43</td>\n",
       "      <td>96.16</td>\n",
       "      <td>532.790740</td>\n",
       "      <td>0.470560</td>\n",
       "      <td>[[251.3, 0.7, 0.4, 2.0, 1.4, 0.7], [0.8, 287.5...</td>\n",
       "      <td>[{'criterion': 'entropy'}, {'criterion': 'entr...</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.79</td>\n",
       "      <td>63.93</td>\n",
       "      <td>64.73</td>\n",
       "      <td>19.732480</td>\n",
       "      <td>1.175560</td>\n",
       "      <td>[[170.6, 6.1, 0.7, 33.3, 6.4, 39.4], [8.0, 130...</td>\n",
       "      <td>[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ROC Acuracia     F1 tempo(s) treino tempo(s) predição  \\\n",
       "0  99.90    99.14  99.08     6113.609690          1.533610   \n",
       "1  99.65    99.15  99.12      196.105840         46.677820   \n",
       "2  99.08    88.58  88.72     7816.920090         65.981150   \n",
       "3  97.73    96.43  96.16      532.790740          0.470560   \n",
       "4  88.79    63.93  64.73       19.732480          1.175560   \n",
       "\n",
       "                                              matriz  \\\n",
       "0  [[255.3, 0.1, 0.2, 0.2, 0.6, 0.1], [0.3, 290.5...   \n",
       "1  [[254.8, 0.9, 0.0, 0.2, 0.6, 0.0], [0.3, 291.4...   \n",
       "2  [[208.6, 1.1, 0.5, 44.6, 1.4, 0.3], [0.4, 278....   \n",
       "3  [[251.3, 0.7, 0.4, 2.0, 1.4, 0.7], [0.8, 287.5...   \n",
       "4  [[170.6, 6.1, 0.7, 33.3, 6.4, 39.4], [8.0, 130...   \n",
       "\n",
       "                                   hiper paramentros                    modelo  \n",
       "0  [{'activation': 'tanh', 'hidden_layer_sizes': ...           MLPClassifier()  \n",
       "1  [{'metric': 'euclidean', 'n_neighbors': 3}, {'...    KNeighborsClassifier()  \n",
       "2  [{'kernel': 'poly', 'probability': True, 'verb...                     SVC()  \n",
       "3  [{'criterion': 'entropy'}, {'criterion': 'entr...  DecisionTreeClassifier()  \n",
       "4           [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]              GaussianNB()  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_pd = pd.DataFrame(resultado)\n",
    "resultado_pd.columns = [\"ROC\", \"Acuracia\", \"F1\", \"tempo(s) treino\",\"tempo(s) predição\", \"matriz\", \"hiper paramentros\", \"modelo\"]\n",
    "resultado_pd[\"ROC\"] = resultado_pd[\"ROC\"].apply(lambda x:  \"%.2f\" % (float(x)*100))  \n",
    "resultado_pd[\"Acuracia\"] = resultado_pd[\"Acuracia\"].apply(lambda x:  \"%.2f\" % (float(x)*100))  \n",
    "resultado_pd[\"F1\"] = resultado_pd[\"F1\"].apply(lambda x:  \"%.2f\" % (float(x)*100))  \n",
    "resultado_pd[\"tempo(s) treino\"] = resultado_pd[\"tempo(s) treino\"].apply(lambda x:  \"%.6f\" % (float(x)*100))  \n",
    "resultado_pd[\"tempo(s) predição\"] = resultado_pd[\"tempo(s) predição\"].apply(lambda x:  \"%.6f\" % (float(x)*100))  \n",
    "resultado_pd.to_csv(\"resultados_best.csv\") # adiciona svm\n",
    "resultado_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC</th>\n",
       "      <th>Acuracia</th>\n",
       "      <th>F1</th>\n",
       "      <th>tempo(s) treino</th>\n",
       "      <th>tempo(s) predição</th>\n",
       "      <th>matriz</th>\n",
       "      <th>hiper paramentros</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.90</td>\n",
       "      <td>99.14</td>\n",
       "      <td>99.08</td>\n",
       "      <td>6113.609690</td>\n",
       "      <td>1.533610</td>\n",
       "      <td>[[255.3, 0.1, 0.2, 0.2, 0.6, 0.1], [0.3, 290.5...</td>\n",
       "      <td>[{'activation': 'tanh', 'hidden_layer_sizes': ...</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.65</td>\n",
       "      <td>99.15</td>\n",
       "      <td>99.12</td>\n",
       "      <td>196.105840</td>\n",
       "      <td>46.677820</td>\n",
       "      <td>[[254.8, 0.9, 0.0, 0.2, 0.6, 0.0], [0.3, 291.4...</td>\n",
       "      <td>[{'metric': 'euclidean', 'n_neighbors': 3}, {'...</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.08</td>\n",
       "      <td>88.58</td>\n",
       "      <td>88.72</td>\n",
       "      <td>7816.920090</td>\n",
       "      <td>65.981150</td>\n",
       "      <td>[[208.6, 1.1, 0.5, 44.6, 1.4, 0.3], [0.4, 278....</td>\n",
       "      <td>[{'kernel': 'poly', 'probability': True, 'verb...</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.73</td>\n",
       "      <td>96.43</td>\n",
       "      <td>96.16</td>\n",
       "      <td>532.790740</td>\n",
       "      <td>0.470560</td>\n",
       "      <td>[[251.3, 0.7, 0.4, 2.0, 1.4, 0.7], [0.8, 287.5...</td>\n",
       "      <td>[{'criterion': 'entropy'}, {'criterion': 'entr...</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.79</td>\n",
       "      <td>63.93</td>\n",
       "      <td>64.73</td>\n",
       "      <td>19.732480</td>\n",
       "      <td>1.175560</td>\n",
       "      <td>[[170.6, 6.1, 0.7, 33.3, 6.4, 39.4], [8.0, 130...</td>\n",
       "      <td>[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ROC Acuracia     F1 tempo(s) treino tempo(s) predição  \\\n",
       "0  99.90    99.14  99.08     6113.609690          1.533610   \n",
       "1  99.65    99.15  99.12      196.105840         46.677820   \n",
       "2  99.08    88.58  88.72     7816.920090         65.981150   \n",
       "3  97.73    96.43  96.16      532.790740          0.470560   \n",
       "4  88.79    63.93  64.73       19.732480          1.175560   \n",
       "\n",
       "                                              matriz  \\\n",
       "0  [[255.3, 0.1, 0.2, 0.2, 0.6, 0.1], [0.3, 290.5...   \n",
       "1  [[254.8, 0.9, 0.0, 0.2, 0.6, 0.0], [0.3, 291.4...   \n",
       "2  [[208.6, 1.1, 0.5, 44.6, 1.4, 0.3], [0.4, 278....   \n",
       "3  [[251.3, 0.7, 0.4, 2.0, 1.4, 0.7], [0.8, 287.5...   \n",
       "4  [[170.6, 6.1, 0.7, 33.3, 6.4, 39.4], [8.0, 130...   \n",
       "\n",
       "                                   hiper paramentros                    modelo  \n",
       "0  [{'activation': 'tanh', 'hidden_layer_sizes': ...           MLPClassifier()  \n",
       "1  [{'metric': 'euclidean', 'n_neighbors': 3}, {'...    KNeighborsClassifier()  \n",
       "2  [{'kernel': 'poly', 'probability': True, 'verb...                     SVC()  \n",
       "3  [{'criterion': 'entropy'}, {'criterion': 'entr...  DecisionTreeClassifier()  \n",
       "4           [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]              GaussianNB()  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resultado_pd.drop(\"matriz\", axis=1).to_csv(\"resultados_best_sem_matriz.csv\")\n",
    "resultado_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'matrizes_best/matriz_MLPClassifier.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20356/3282007120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mmatriz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"matrizes_best/matriz_{}.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msave_matriz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultado_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"matriz\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultado_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"modelo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20356/3282007120.py\u001b[0m in \u001b[0;36msave_matriz\u001b[1;34m(matrizes, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmatriz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmatriz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mmatriz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"matrizes_best/matriz_{}.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msave_matriz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultado_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"matriz\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultado_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"modelo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'matrizes_best/matriz_MLPClassifier.csv'"
     ]
    }
   ],
   "source": [
    "def save_matriz(matrizes, model):\n",
    "    for ma, mo in zip(matrizes, model):\n",
    "        matriz = pd.DataFrame(ma)\n",
    "        matriz.columns = list(range(1,7))\n",
    "        matriz.index = list(range(1,7))\n",
    "        matriz.to_csv(\"matrizes_best/matriz_{}.csv\".format(mo[:-2]))\n",
    "\n",
    "save_matriz(resultado_pd[\"matriz\"], resultado_pd[\"modelo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f6ca866bada2297d8fd83be4f6138ccbd7745b9651ccd132432817d094bcf3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
