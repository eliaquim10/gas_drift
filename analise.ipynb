{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise de dados de hipotiroidismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# Classes dos modelo\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Funções de avaliação dos modelos\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "# sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V121</th>\n",
       "      <th>V122</th>\n",
       "      <th>V123</th>\n",
       "      <th>V124</th>\n",
       "      <th>V125</th>\n",
       "      <th>V126</th>\n",
       "      <th>V127</th>\n",
       "      <th>V128</th>\n",
       "      <th>V129</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12285.6582</td>\n",
       "      <td>4.076635</td>\n",
       "      <td>4.842317</td>\n",
       "      <td>7.509393</td>\n",
       "      <td>10.822436</td>\n",
       "      <td>-1.312657</td>\n",
       "      <td>-1.853717</td>\n",
       "      <td>-6.924985</td>\n",
       "      <td>11800.9233</td>\n",
       "      <td>4.483500</td>\n",
       "      <td>...</td>\n",
       "      <td>1784.5324</td>\n",
       "      <td>1.907000</td>\n",
       "      <td>1.729200</td>\n",
       "      <td>4.881194</td>\n",
       "      <td>8.623828</td>\n",
       "      <td>-0.314110</td>\n",
       "      <td>-0.661556</td>\n",
       "      <td>-3.521663</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-35.6889</td>\n",
       "      <td>0.993944</td>\n",
       "      <td>0.166099</td>\n",
       "      <td>0.489363</td>\n",
       "      <td>3.484663</td>\n",
       "      <td>-0.130298</td>\n",
       "      <td>-0.528364</td>\n",
       "      <td>-3.735347</td>\n",
       "      <td>266.4145</td>\n",
       "      <td>1.053988</td>\n",
       "      <td>...</td>\n",
       "      <td>904.9898</td>\n",
       "      <td>1.433707</td>\n",
       "      <td>1.068069</td>\n",
       "      <td>2.532958</td>\n",
       "      <td>5.369720</td>\n",
       "      <td>-0.183779</td>\n",
       "      <td>-0.534087</td>\n",
       "      <td>-4.635975</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63927.2217</td>\n",
       "      <td>14.956941</td>\n",
       "      <td>19.971376</td>\n",
       "      <td>29.188512</td>\n",
       "      <td>33.291320</td>\n",
       "      <td>-10.433776</td>\n",
       "      <td>-16.062245</td>\n",
       "      <td>-49.490143</td>\n",
       "      <td>57405.8483</td>\n",
       "      <td>15.613843</td>\n",
       "      <td>...</td>\n",
       "      <td>14585.7879</td>\n",
       "      <td>8.189021</td>\n",
       "      <td>6.099452</td>\n",
       "      <td>12.127991</td>\n",
       "      <td>15.709651</td>\n",
       "      <td>-3.887082</td>\n",
       "      <td>-6.731473</td>\n",
       "      <td>-19.326895</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2992.9019</td>\n",
       "      <td>1.380553</td>\n",
       "      <td>0.808910</td>\n",
       "      <td>1.288259</td>\n",
       "      <td>4.660135</td>\n",
       "      <td>-0.755903</td>\n",
       "      <td>-1.120470</td>\n",
       "      <td>-4.075213</td>\n",
       "      <td>4301.4033</td>\n",
       "      <td>1.652701</td>\n",
       "      <td>...</td>\n",
       "      <td>6044.5554</td>\n",
       "      <td>3.488295</td>\n",
       "      <td>2.662288</td>\n",
       "      <td>5.938297</td>\n",
       "      <td>8.544508</td>\n",
       "      <td>-1.567322</td>\n",
       "      <td>-2.701235</td>\n",
       "      <td>-6.472439</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57524.7812</td>\n",
       "      <td>11.912566</td>\n",
       "      <td>14.631496</td>\n",
       "      <td>19.809240</td>\n",
       "      <td>23.715868</td>\n",
       "      <td>-9.084750</td>\n",
       "      <td>-11.770585</td>\n",
       "      <td>-39.234003</td>\n",
       "      <td>50051.0703</td>\n",
       "      <td>11.732548</td>\n",
       "      <td>...</td>\n",
       "      <td>10580.1006</td>\n",
       "      <td>5.752675</td>\n",
       "      <td>3.880740</td>\n",
       "      <td>8.545897</td>\n",
       "      <td>11.831716</td>\n",
       "      <td>-2.655521</td>\n",
       "      <td>-4.312744</td>\n",
       "      <td>-8.510591</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1         V2         V3         V4         V5         V6  \\\n",
       "0  12285.6582   4.076635   4.842317   7.509393  10.822436  -1.312657   \n",
       "1    -35.6889   0.993944   0.166099   0.489363   3.484663  -0.130298   \n",
       "2  63927.2217  14.956941  19.971376  29.188512  33.291320 -10.433776   \n",
       "3   2992.9019   1.380553   0.808910   1.288259   4.660135  -0.755903   \n",
       "4  57524.7812  11.912566  14.631496  19.809240  23.715868  -9.084750   \n",
       "\n",
       "          V7         V8          V9        V10  ...        V121      V122  \\\n",
       "0  -1.853717  -6.924985  11800.9233   4.483500  ...   1784.5324  1.907000   \n",
       "1  -0.528364  -3.735347    266.4145   1.053988  ...    904.9898  1.433707   \n",
       "2 -16.062245 -49.490143  57405.8483  15.613843  ...  14585.7879  8.189021   \n",
       "3  -1.120470  -4.075213   4301.4033   1.652701  ...   6044.5554  3.488295   \n",
       "4 -11.770585 -39.234003  50051.0703  11.732548  ...  10580.1006  5.752675   \n",
       "\n",
       "       V123       V124       V125      V126      V127       V128   V129  Class  \n",
       "0  1.729200   4.881194   8.623828 -0.314110 -0.661556  -3.521663   10.0      4  \n",
       "1  1.068069   2.532958   5.369720 -0.183779 -0.534087  -4.635975   50.0      3  \n",
       "2  6.099452  12.127991  15.709651 -3.887082 -6.731473 -19.326895  250.0      4  \n",
       "3  2.662288   5.938297   8.544508 -1.567322 -2.701235  -6.472439  600.0      3  \n",
       "4  3.880740   8.545897  11.831716 -2.655521 -4.312744  -8.510591  150.0      4  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = pd.read_csv(\"dataset_57_hypothyroid.csv\")\n",
    "dataset = pd.read_csv(\"phpN4gaxw.csv\")\n",
    "dataset.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13910, 130)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13910, 130)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3009\n",
       "2    2926\n",
       "1    2565\n",
       "4    1936\n",
       "6    1833\n",
       "3    1641\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 0\n",
      "V1 13910\n",
      "V2 0\n",
      "V2 13910\n",
      "V3 0\n",
      "V3 13910\n",
      "V4 0\n",
      "V4 13910\n",
      "V5 0\n",
      "V5 13910\n",
      "V6 0\n",
      "V6 13910\n",
      "V7 0\n",
      "V7 13910\n",
      "V8 0\n",
      "V8 13910\n",
      "V9 0\n",
      "V9 13910\n",
      "V10 0\n",
      "V10 13910\n",
      "V11 0\n",
      "V11 13910\n",
      "V12 0\n",
      "V12 13910\n",
      "V13 0\n",
      "V13 13910\n",
      "V14 0\n",
      "V14 13910\n",
      "V15 0\n",
      "V15 13910\n",
      "V16 0\n",
      "V16 13910\n",
      "V17 0\n",
      "V17 13910\n",
      "V18 0\n",
      "V18 13910\n",
      "V19 0\n",
      "V19 13910\n",
      "V20 0\n",
      "V20 13910\n",
      "V21 0\n",
      "V21 13910\n",
      "V22 0\n",
      "V22 13910\n",
      "V23 0\n",
      "V23 13910\n",
      "V24 0\n",
      "V24 13910\n",
      "V25 0\n",
      "V25 13910\n",
      "V26 0\n",
      "V26 13910\n",
      "V27 0\n",
      "V27 13910\n",
      "V28 0\n",
      "V28 13910\n",
      "V29 0\n",
      "V29 13910\n",
      "V30 0\n",
      "V30 13910\n",
      "V31 0\n",
      "V31 13910\n",
      "V32 0\n",
      "V32 13910\n",
      "V33 0\n",
      "V33 13910\n",
      "V34 0\n",
      "V34 13910\n",
      "V35 0\n",
      "V35 13910\n",
      "V36 0\n",
      "V36 13910\n",
      "V37 0\n",
      "V37 13910\n",
      "V38 0\n",
      "V38 13910\n",
      "V39 0\n",
      "V39 13910\n",
      "V40 0\n",
      "V40 13910\n",
      "V41 0\n",
      "V41 13910\n",
      "V42 0\n",
      "V42 13910\n",
      "V43 0\n",
      "V43 13910\n",
      "V44 0\n",
      "V44 13910\n",
      "V45 0\n",
      "V45 13910\n",
      "V46 0\n",
      "V46 13910\n",
      "V47 0\n",
      "V47 13910\n",
      "V48 0\n",
      "V48 13910\n",
      "V49 0\n",
      "V49 13910\n",
      "V50 0\n",
      "V50 13910\n",
      "V51 0\n",
      "V51 13910\n",
      "V52 0\n",
      "V52 13910\n",
      "V53 0\n",
      "V53 13910\n",
      "V54 0\n",
      "V54 13910\n",
      "V55 0\n",
      "V55 13910\n",
      "V56 0\n",
      "V56 13910\n",
      "V57 0\n",
      "V57 13910\n",
      "V58 0\n",
      "V58 13910\n",
      "V59 0\n",
      "V59 13910\n",
      "V60 0\n",
      "V60 13910\n",
      "V61 0\n",
      "V61 13910\n",
      "V62 0\n",
      "V62 13910\n",
      "V63 0\n",
      "V63 13910\n",
      "V64 0\n",
      "V64 13910\n",
      "V65 0\n",
      "V65 13910\n",
      "V66 0\n",
      "V66 13910\n",
      "V67 0\n",
      "V67 13910\n",
      "V68 0\n",
      "V68 13910\n",
      "V69 0\n",
      "V69 13910\n",
      "V70 0\n",
      "V70 13910\n",
      "V71 0\n",
      "V71 13910\n",
      "V72 0\n",
      "V72 13910\n",
      "V73 0\n",
      "V73 13910\n",
      "V74 0\n",
      "V74 13910\n",
      "V75 0\n",
      "V75 13910\n",
      "V76 0\n",
      "V76 13910\n",
      "V77 0\n",
      "V77 13910\n",
      "V78 0\n",
      "V78 13910\n",
      "V79 0\n",
      "V79 13910\n",
      "V80 0\n",
      "V80 13910\n",
      "V81 0\n",
      "V81 13910\n",
      "V82 0\n",
      "V82 13910\n",
      "V83 0\n",
      "V83 13910\n",
      "V84 0\n",
      "V84 13910\n",
      "V85 0\n",
      "V85 13910\n",
      "V86 0\n",
      "V86 13910\n",
      "V87 0\n",
      "V87 13910\n",
      "V88 0\n",
      "V88 13910\n",
      "V89 0\n",
      "V89 13910\n",
      "V90 0\n",
      "V90 13910\n",
      "V91 0\n",
      "V91 13910\n",
      "V92 0\n",
      "V92 13910\n",
      "V93 0\n",
      "V93 13910\n",
      "V94 0\n",
      "V94 13910\n",
      "V95 0\n",
      "V95 13910\n",
      "V96 0\n",
      "V96 13910\n",
      "V97 0\n",
      "V97 13910\n",
      "V98 0\n",
      "V98 13910\n",
      "V99 0\n",
      "V99 13910\n",
      "V100 0\n",
      "V100 13910\n",
      "V101 0\n",
      "V101 13910\n",
      "V102 0\n",
      "V102 13910\n",
      "V103 0\n",
      "V103 13910\n",
      "V104 0\n",
      "V104 13910\n",
      "V105 0\n",
      "V105 13910\n",
      "V106 0\n",
      "V106 13910\n",
      "V107 0\n",
      "V107 13910\n",
      "V108 0\n",
      "V108 13910\n",
      "V109 0\n",
      "V109 13910\n",
      "V110 0\n",
      "V110 13910\n",
      "V111 0\n",
      "V111 13910\n",
      "V112 0\n",
      "V112 13910\n",
      "V113 0\n",
      "V113 13910\n",
      "V114 0\n",
      "V114 13910\n",
      "V115 0\n",
      "V115 13910\n",
      "V116 0\n",
      "V116 13910\n",
      "V117 0\n",
      "V117 13910\n",
      "V118 0\n",
      "V118 13910\n",
      "V119 0\n",
      "V119 13910\n",
      "V120 0\n",
      "V120 13910\n",
      "V121 0\n",
      "V121 13910\n",
      "V122 0\n",
      "V122 13910\n",
      "V123 0\n",
      "V123 13910\n",
      "V124 0\n",
      "V124 13910\n",
      "V125 0\n",
      "V125 13910\n",
      "V126 0\n",
      "V126 13910\n",
      "V127 0\n",
      "V127 13910\n",
      "V128 0\n",
      "V128 13910\n",
      "V129 0\n",
      "V129 13910\n",
      "Class 0\n",
      "Class 13910\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for column in dataset:\n",
    "  print(column, (dataset[column] == \"?\").sum() )\n",
    "  print(column, (dataset[column].notna()).sum() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"TSH\"] = dataset[\"TSH\"].astype(\"float\")\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cont_labels(samples):\n",
    "  values = {}\n",
    "  for sample in samples:\n",
    "    if values.get(sample) != None:\n",
    "      values[sample] += 1\n",
    "    else:\n",
    "      values[sample] = 1\n",
    "  return [values[i] for i in range(min(values.keys()), max(values.keys()))]\n",
    "\n",
    "def classifier(model_name, model, X_train, y_train, y_test):\n",
    "  print(\"=\"*30, model_name, \"=\"*30)\n",
    "  model.fit(X_train, y_train)\n",
    "  y_predict = regression_model.predict(X_test)\n",
    "  print(classification_report(y_test, y_predict))\n",
    "  # print(roc_curve(cont_labels(y_test)[:2], cont_labels(y_predict)[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Regressão Logistica 1 ==============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.84      0.69      1283\n",
      "           2       0.91      0.80      0.85      1463\n",
      "           3       0.33      0.82      0.47       821\n",
      "           4       0.38      0.21      0.27       968\n",
      "           5       0.99      0.25      0.40      1504\n",
      "           6       0.99      0.90      0.94       916\n",
      "\n",
      "    accuracy                           0.62      6955\n",
      "   macro avg       0.70      0.64      0.60      6955\n",
      "weighted avg       0.73      0.62      0.61      6955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eliaquim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {1283, 1463} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-65f52638cade>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m   \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Regressão Logistica {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-6b143806a630>\u001b[0m in \u001b[0;36mclassifier\u001b[1;34m(model_name, model, X_train, y_train, y_test)\u001b[0m\n\u001b[0;32m     16\u001b[0m   \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregression_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcont_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m     \"\"\"\n\u001b[1;32m--> 913\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[0;32m    914\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m     \u001b[0mpos_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_pos_label_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;31m# make y_true a boolean vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_check_pos_label_consistency\u001b[1;34m(pos_label, y_true)\u001b[0m\n\u001b[0;32m    241\u001b[0m                  np.array_equal(classes, [1])))):\n\u001b[0;32m    242\u001b[0m         \u001b[0mclasses_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\", \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;34mf\"y_true takes value in {{{classes_repr}}} and pos_label is not \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;34mf\"specified: either make y_true take value in {{0, 1}} or \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true takes value in {1283, 1463} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "y = dataset[\"Class\"]\n",
    "X = dataset.drop([\"Class\"], axis=1)\n",
    "X = X.astype(\"float64\")\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.30, random_state=199)\n",
    "\n",
    "for n_round, (train_index, test_index) in enumerate(skf.split(X, y), start=1):\n",
    "  regression_model = LogisticRegression()\n",
    "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "  classifier(\"Regressão Logistica {}\".format(n_round), regression_model, X_train, y_train, y_test)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_fpr = np.unique(np.concatenate([fpr[i] for i in range(10)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24d649e7070>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_a = 1\n",
    "class_b = 2\n",
    "class_c = 3\n",
    "class_d = 4\n",
    "class_e = 5\n",
    "class_f = 6\n",
    "class_0_instances = y == class_a\n",
    "class_1_instances = y == class_b\n",
    "class_2_instances = y == class_c\n",
    "class_3_instances = y == class_d\n",
    "class_4_instances = y == class_e\n",
    "class_5_instances = y == class_f\n",
    "feature_0 = \"V128\"\n",
    "feature_1 = \"Class\"\n",
    "\n",
    "colors = {1: \"blue\", 2: \"orange\", 3: \"red\", 4: \"green\", 5: \"green\", 6: \"yellow\"}\n",
    "markers = {1: \"s\", 2: \"^\", 3:\"o\", 4: \"*\", 5: \".\", 6: \"+\"}\n",
    "\n",
    "plt.scatter(\n",
    "    dataset[feature_0][class_0_instances],\n",
    "    dataset[feature_1][class_0_instances], \n",
    "    c=colors[class_a], \n",
    "    marker=markers[class_a]\n",
    ")\n",
    "plt.scatter(\n",
    "    dataset[feature_0][class_1_instances], \n",
    "    dataset[feature_1][class_1_instances], \n",
    "    c=colors[class_b], \n",
    "    marker=markers[class_b]\n",
    ")\n",
    "plt.scatter(\n",
    "    dataset[feature_0][class_2_instances], \n",
    "    dataset[feature_1][class_2_instances], \n",
    "    c=colors[class_c], \n",
    "    marker=markers[class_c]\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    dataset[feature_0][class_3_instances], \n",
    "    dataset[feature_1][class_3_instances], \n",
    "    c=colors[class_d], \n",
    "    marker=markers[class_d]\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    dataset[feature_0][class_4_instances], \n",
    "    dataset[feature_1][class_4_instances], \n",
    "    c=colors[class_e], \n",
    "    marker=markers[class_e]\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    dataset[feature_0][class_5_instances], \n",
    "    dataset[feature_1][class_5_instances], \n",
    "    c=colors[class_f], \n",
    "    marker=markers[class_f]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f6ca866bada2297d8fd83be4f6138ccbd7745b9651ccd132432817d094bcf3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
